{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1WNN7lAwNPRD",
      "metadata": {
        "id": "1WNN7lAwNPRD"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "OqBDNX7tnO7w",
      "metadata": {
        "id": "OqBDNX7tnO7w",
        "outputId": "f097bd73-7572-4f77-f680-442bcef9ffc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/99.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.6/99.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade --quiet langchain langchain_google_community langchain_google_vertexai google-cloud-discoveryengine google_cloud_aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fsG9CSrOFzHt",
      "metadata": {
        "id": "fsG9CSrOFzHt",
        "outputId": "37977ed6-25dd-4e29-e885-10b4f87c6314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "O1yHvoyXFaPc",
      "metadata": {
        "id": "O1yHvoyXFaPc"
      },
      "outputs": [],
      "source": [
        "# Authenticate with Colab (if you're using Google Colab)\n",
        "\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()\n",
        "\n",
        "from google.auth import default\n",
        "creds, _ = default()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "NbO6qHY2IKDg",
      "metadata": {
        "id": "NbO6qHY2IKDg"
      },
      "outputs": [],
      "source": [
        "# Set your project and region\n",
        "PROJECT_ID = \"commsenglabs-poc-4187240\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "LOCATION = \"global\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ruFJiEYpGQ50",
      "metadata": {
        "id": "ruFJiEYpGQ50",
        "outputId": "e8e67949-f5af-4cdb-a7e0-24dcc0b04e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "# This cell is only needed if you run Google Colab\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "! gcloud config set project {PROJECT_ID}\n",
        "#! gcloud auth application-default login\n",
        "#! gcloud auth application-default set-quota-project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DH-Hsd-pNSN4",
      "metadata": {
        "id": "DH-Hsd-pNSN4"
      },
      "source": [
        "# Hallucinations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A7lPJMqOM6Fn",
      "metadata": {
        "id": "A7lPJMqOM6Fn"
      },
      "source": [
        "## How prompt engineering helps to avoid hallucinations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DEf4Rxl6F_Rw",
      "metadata": {
        "id": "DEf4Rxl6F_Rw"
      },
      "source": [
        "Hallucinations are a real problem for LLMs. Since the LLM completes text that is plausible, it can be tricked into creating plausible, but completely false responses. Please take note that we are intentionally using an \"old\" model here, as newer model have much better built-in guardrailes. Here's a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fon_e0FgF-hA",
      "metadata": {
        "id": "fon_e0FgF-hA",
        "outputId": "eea320a2-0486-4732-970b-a5ce8ae4135e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2351814274.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt_template)\n",
            "/tmp/ipython-input-2351814274.py:19: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  chain.run(plant=\"black cucumbers\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Black cucumbers are a fascinating and somewhat misleading name! There aren\\'t cucumbers that are truly black in the same way that, say, a black olive or black grape is. However, there are a few reasons why a cucumber might be described as \"black\":\\n\\n*   **Very Dark Green:** The term \"black cucumber\" is most often used to describe cucumbers that are a very deep, dark green color. This can be so dark that they appear almost black, especially from a distance or in certain lighting. This dark color is often due to specific varieties or growing conditions.\\n\\n*   **Immature Stage:** Some cucumber varieties may'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "\n",
        "llm = VertexAI(model_name=\"gemini-2.0-flash-001\", temperature=0.8, max_output_tokens=128)\n",
        "\n",
        "template = \"\"\"Describe {plant}.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "   input_variables=[\"plant\"],\n",
        "   template=template,\n",
        ")\n",
        "\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "chain.run(plant=\"black cucumbers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8JLGjw4M8tI",
      "metadata": {
        "id": "f8JLGjw4M8tI"
      },
      "source": [
        "Let's look at a simple prompt adjustment that helps to avoid hallucinations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Az5cbdYNGCOMpfjIjTBBjN1u",
      "metadata": {
        "id": "Az5cbdYNGCOMpfjIjTBBjN1u",
        "tags": [],
        "outputId": "5e2a178a-6243-4458-abfb-c331136b3a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, black cucumbers do exist.\\n\\n**Title:** Black Cucumber (Also sometimes called Black Serpent Cucumber)\\n\\n**Summary:** Black cucumbers are a unique variety of cucumber known for their dark green, almost black skin. They offer a slightly sweet and mild flavor, making them a refreshing addition to salads, snacks, and various culinary dishes.\\n\\n**Origin and Cultivation:** The exact origin of the black cucumber is somewhat vague, but they are believed to be derived from Asian varieties. They are relatively easy to grow, similar to other cucumber varieties. They thrive in warm weather, well-drained soil, and require consistent watering. Seeds can'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "\n",
        "llm = VertexAI(model_name=\"gemini-2.0-flash-001\", temperature=0.8, max_output_tokens=128)\n",
        "\n",
        "template = \"\"\"Describe {plant}.\n",
        "\n",
        "\n",
        "First, think whether {plant} exist.\n",
        "If {plant} doesn't exist, answer \"I don't have enough information about {plant}\".\n",
        "Otherwise, give its title, a short summary and then talk about origin and cultivation.\n",
        "After that, describe its physical characteristics.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "   input_variables=[\"plant\"],\n",
        "   template=template,\n",
        ")\n",
        "\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "chain.run(plant=\"black cucumbers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h87kNLX_ULyS",
      "metadata": {
        "id": "h87kNLX_ULyS"
      },
      "source": [
        "# Vertex AI Agent Builder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aVw2HajqUNLg",
      "metadata": {
        "id": "aVw2HajqUNLg"
      },
      "source": [
        "## Using Vertex AI Agent Builder as a tool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PgAgN1CzUOyJ",
      "metadata": {
        "id": "PgAgN1CzUOyJ"
      },
      "source": [
        "Vertex AI Agent Builder provides an end-to-end experience for build out-of-the-box RAG agents. You will find relevant documents and be able to prepare a final answer with generative AI. You can use it as a tool. We will look in Chapter 9 what tools are and how they help to build powerful generative AI agents, but all we need to know for now is that Vertex AI Agent Builder is an interface that takes a question as an input and returns an answer.\n",
        "\n",
        "Check the [Google Cloud Documentation](https://cloud.google.com/products/agent-builder?e=0&hl=en#use-vertex-ai-search-for-out-of-the-box-rag-for-your-agents-and-apps) for a deep discussion of Vertex AI Agent Builder for Search."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P5QaB5BfUxyX",
      "metadata": {
        "id": "P5QaB5BfUxyX"
      },
      "source": [
        "Vertex AI Agent Builder uses so-called Data Stores for running its code. Follow the instructions in the book on how to set up your datastore, and after you created it, you can use it with LangChain:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pFHW3Vt1u_gA",
      "metadata": {
        "id": "pFHW3Vt1u_gA"
      },
      "source": [
        "### Creating the Datastore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fNlOt8vSvB1q",
      "metadata": {
        "id": "fNlOt8vSvB1q"
      },
      "source": [
        "First, we need to create the datastore. This is the place, where you will hold the data that flows into your RAG. Confusingly, it uses something called a Discoveryengine. Check the documentation for details on datastores [here](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "zsqfVLRDvBdP",
      "metadata": {
        "id": "zsqfVLRDvBdP"
      },
      "outputs": [],
      "source": [
        "# Let's start with with some helper functions\n",
        "def create_data_store(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    data_store_id: str,\n",
        ") -> str:\n",
        "    #  For more information, refer to:\n",
        "    # https://cloud.google.com/generative-ai-app-builder/docs/locations#specify_a_multi-region_for_your_data_store\n",
        "    client_options = (\n",
        "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
        "        if location != \"global\"\n",
        "        else None\n",
        "    )\n",
        "\n",
        "    # Create a client\n",
        "    client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n",
        "\n",
        "    # The full resource name of the collection\n",
        "    # e.g. projects/{project}/locations/{location}/collections/default_collection\n",
        "    parent = client.collection_path(\n",
        "        project=project_id,\n",
        "        location=location,\n",
        "        collection=\"default_collection\",\n",
        "    )\n",
        "\n",
        "    data_store = discoveryengine.DataStore(\n",
        "        display_name=\"My Data Store\",\n",
        "        # Options: GENERIC, MEDIA, HEALTHCARE_FHIR\n",
        "        industry_vertical=discoveryengine.IndustryVertical.GENERIC,\n",
        "        # Options: SOLUTION_TYPE_RECOMMENDATION, SOLUTION_TYPE_SEARCH, SOLUTION_TYPE_CHAT, SOLUTION_TYPE_GENERATIVE_CHAT\n",
        "        solution_types=[discoveryengine.SolutionType.SOLUTION_TYPE_SEARCH],\n",
        "        # TODO(developer): Update content_config based on data store type.\n",
        "        # Options: NO_CONTENT, CONTENT_REQUIRED, PUBLIC_WEBSITE\n",
        "        content_config=discoveryengine.DataStore.ContentConfig.CONTENT_REQUIRED,\n",
        "    )\n",
        "\n",
        "    request = discoveryengine.CreateDataStoreRequest(\n",
        "        parent=parent,\n",
        "        data_store_id=data_store_id,\n",
        "        data_store=data_store,\n",
        "        # Optional: For Advanced Site Search Only\n",
        "        # create_advanced_site_search=True,\n",
        "    )\n",
        "\n",
        "    # Make the request\n",
        "    operation = client.create_data_store(request=request)\n",
        "\n",
        "    print(f\"Waiting for operation to complete: {operation.operation.name}\")\n",
        "    response = operation.result()\n",
        "\n",
        "    # Once the operation is complete,\n",
        "    # get information from operation metadata\n",
        "    metadata = discoveryengine.CreateDataStoreMetadata(operation.metadata)\n",
        "\n",
        "    # Handle the response\n",
        "    print(response)\n",
        "    print(metadata)\n",
        "\n",
        "    return operation.operation.name\n",
        "\n",
        "def import_documents(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    data_store_id: str,\n",
        "    gcs_uri: str,\n",
        "    ):\n",
        "    # Create a client\n",
        "    client_options = (\n",
        "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
        "        if location != \"global\"\n",
        "        else None\n",
        "    )\n",
        "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
        "\n",
        "    # The full resource name of the search engine branch.\n",
        "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
        "    parent = client.branch_path(\n",
        "        project=project_id,\n",
        "        location=location,\n",
        "        data_store=data_store_id,\n",
        "        branch=\"default_branch\",\n",
        "    )\n",
        "    source_documents = [f\"{gcs_uri}/*\"]\n",
        "\n",
        "    request = discoveryengine.ImportDocumentsRequest(\n",
        "        parent=parent,\n",
        "        gcs_source=discoveryengine.GcsSource(\n",
        "            input_uris=source_documents, data_schema=\"content\"\n",
        "        ),\n",
        "        # Options: `FULL`, `INCREMENTAL`\n",
        "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
        "    )\n",
        "\n",
        "    # Make the request\n",
        "    operation = client.import_documents(request=request)\n",
        "\n",
        "    response = operation.result()\n",
        "\n",
        "    # Once the operation is complete,\n",
        "    # get information from operation metadata\n",
        "    metadata = discoveryengine.ImportDocumentsMetadata(operation.metadata)\n",
        "\n",
        "    # Handle the response\n",
        "    return operation.operation.name\n",
        "\n",
        "def create_engine(\n",
        "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
        "  ):\n",
        "    # Create a client\n",
        "    client_options = (\n",
        "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
        "        if location != \"global\"\n",
        "        else None\n",
        "    )\n",
        "    client = discoveryengine.EngineServiceClient(client_options=client_options)\n",
        "\n",
        "    # Initialize request argument(s)\n",
        "    config = discoveryengine.Engine.SearchEngineConfig(\n",
        "        search_tier=\"SEARCH_TIER_ENTERPRISE\", search_add_ons=[\"SEARCH_ADD_ON_LLM\"]\n",
        "    )\n",
        "\n",
        "    engine = discoveryengine.Engine(\n",
        "        display_name=data_store_name,\n",
        "        solution_type=\"SOLUTION_TYPE_SEARCH\",\n",
        "        industry_vertical=\"GENERIC\",\n",
        "        data_store_ids=[data_store_id],\n",
        "        search_engine_config=config,\n",
        "    )\n",
        "\n",
        "    request = discoveryengine.CreateEngineRequest(\n",
        "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
        "            project_id, location, \"default_collection\"\n",
        "        ),\n",
        "        engine=engine,\n",
        "        engine_id=engine.display_name,\n",
        "    )\n",
        "\n",
        "    # Make the request\n",
        "    operation = client.create_engine(request=request)\n",
        "    response = operation.result(timeout=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "sgBwubY9UTj2",
      "metadata": {
        "id": "sgBwubY9UTj2",
        "outputId": "c173c629-010a-43d9-bb64-91360df58df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "PermissionDenied",
          "evalue": "403 Discovery Engine API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"discoveryengine.googleapis.com\"\n}\nmetadata {\n  key: \"serviceTitle\"\n  value: \"Discovery Engine API\"\n}\nmetadata {\n  key: \"containerInfo\"\n  value: \"522309567947\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/522309567947\"\n}\nmetadata {\n  key: \"activationUrl\"\n  value: \"https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947\"\n}\n, locale: \"en-US\"\nmessage: \"Discovery Engine API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n, links {\n  description: \"Google developers console API activation\"\n  url: \"https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947\"\n}\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;34m\"\"\"See grpc.Future.result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         )\n\u001b[0;32m-> 1192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Discovery Engine API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:74.125.202.95:443 {grpc_message:\"Discovery Engine API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\", grpc_status:7}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2445733385.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mDATASTORE_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"movie-database-maxtsc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDATASTORE_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{DATASTORE_NAME}-id\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mCOLLECTION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASTORE_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-87001621.py\u001b[0m in \u001b[0;36mcreate_data_store\u001b[0;34m(project_id, location, data_store_id)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Make the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_data_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Waiting for operation to complete: {operation.operation.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/discoveryengine_v1alpha/services/data_store_service/client.py\u001b[0m in \u001b[0;36mcreate_data_store\u001b[0;34m(self, request, parent, data_store, data_store_id, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionDenied\u001b[0m: 403 Discovery Engine API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"discoveryengine.googleapis.com\"\n}\nmetadata {\n  key: \"serviceTitle\"\n  value: \"Discovery Engine API\"\n}\nmetadata {\n  key: \"containerInfo\"\n  value: \"522309567947\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/522309567947\"\n}\nmetadata {\n  key: \"activationUrl\"\n  value: \"https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947\"\n}\n, locale: \"en-US\"\nmessage: \"Discovery Engine API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n, links {\n  description: \"Google developers console API activation\"\n  url: \"https://console.developers.google.com/apis/api/discoveryengine.googleapis.com/overview?project=522309567947\"\n}\n]"
          ]
        }
      ],
      "source": [
        "from google.cloud import discoveryengine_v1alpha as discoveryengine\n",
        "from google.api_core.client_options import ClientOptions\n",
        "\n",
        "# The datastore name can only contain lowercase letters, numbers, and hyphens\n",
        "DATASTORE_NAME = \"movie-database-maxtsc\"\n",
        "DATASTORE_ID = f\"{DATASTORE_NAME}-id\"\n",
        "COLLECTION = create_data_store(PROJECT_ID, LOCATION, DATASTORE_ID)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xFdWoDUbBykD",
      "metadata": {
        "id": "xFdWoDUbBykD"
      },
      "outputs": [],
      "source": [
        "# Now we need to also set up a search engine on top of the datastore so we can use enterprise features\n",
        "create_engine(PROJECT_ID, LOCATION, DATASTORE_NAME, DATASTORE_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XKF9qg0L_ZWK",
      "metadata": {
        "id": "XKF9qg0L_ZWK"
      },
      "outputs": [],
      "source": [
        "# Now we import documents. We load a folder that contains arxiv articles. This will take some time ☕🥪\n",
        "import_documents(PROJECT_ID, LOCATION, DATASTORE_ID,\"gs://cloud-samples-data/gen-app-builder/search/arxiv\")\n",
        "\n",
        "# Don't worry if it times out, you can check the status in the Agent Builder console and use the tool once it's complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "EtEIn7LJBcZC",
      "metadata": {
        "id": "EtEIn7LJBcZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7779ad55-a124-4f0b-d251-ce99723a7280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_community/vertex_ai_search.py:364: UserWarning: Beta features are configured but beta=False. The following beta features will be ignored:['custom_embedding_ratio']\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No results could be found. Try rephrasing the search query.\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_community import VertexAISearchSummaryTool\n",
        "\n",
        "DATASTORE_NAME = \"alphabet-investor-pdfs\"\n",
        "DATASTORE_ID = \"alphabet-investor-pdfs_1754412379585\"\n",
        "LOCATION = \"us\"\n",
        "vertex_search = VertexAISearchSummaryTool(\n",
        "  project_id=PROJECT_ID, location_id=LOCATION,\n",
        "  data_store_id=DATASTORE_ID, get_extractive_answers = True,\n",
        "  name=\"Vertex AI Agent Builder\", description=\"\")\n",
        "\n",
        "query = \"How many users Youtube had last year?\"\n",
        "\n",
        "print(vertex_search.invoke(query))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SzXL2GYk0MHk",
      "metadata": {
        "id": "SzXL2GYk0MHk"
      },
      "source": [
        "### LangChain Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hNqUBBQiH9xT",
      "metadata": {
        "id": "hNqUBBQiH9xT"
      },
      "source": [
        "Before we dive into building the RAG, it's important to understand how LangChain documents work. Below is a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "BtAlAwUeNdGk",
      "metadata": {
        "id": "BtAlAwUeNdGk",
        "outputId": "ab7628bd-c063-403f-d737-e83c83a550d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my page\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "doc = Document(page_content=\"my page\",\n",
        "              metadata={\"source_id\": \"example.pdf\", \"page\": 1})\n",
        "print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ewFgX0w0OpL",
      "metadata": {
        "id": "9ewFgX0w0OpL"
      },
      "source": [
        "### Using Vertex AI Agent Builder Search as retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sWUaU-qBHmA2",
      "metadata": {
        "id": "sWUaU-qBHmA2"
      },
      "source": [
        "Now we can also use our newly built tool as a retriever to have more control over the context it returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "D-QQISqNVG0h",
      "metadata": {
        "id": "D-QQISqNVG0h",
        "outputId": "1dcc8034-647e-492f-83e2-1d54fd11ca2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "1623 {'id': 'fec239d1570ce88f57a8971c3d6e8415', 'source': 'gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2006_google_annual_report.pdf7', 'previous_segments': [], 'next_segments': [{'content': 'Local\\nPeople use Google products to learn not just about\\nthe farthest reaches of the universe but about places\\ncloser to home. Google MapsTM has become the #1\\nmapping site across Europe and #2 in the U.S., and\\nnow offers detailed street maps in more than 50\\ncountries. We are pleased that so many developers\\nhave used our mapping technology as a platform\\nfor further innovation, and proud that more than\\n30,000 websites use our maps API. Local authorities\\nin London now use the Google Maps API to let\\nresidents report problems such as road defects and\\ntrash on the streets. Google Maps is also available\\nnow on mobile devices and plays an integral role\\nin our partnerships with mobile providers. We expect\\nmore and better local products to result from our\\nwork in the mobile space.\\nWith more than 200 million unique downloads,\\nGoogle EarthTM users worldwide are venturing out to\\nexplore, understand, and share our planet. Google\\nEarth now covers more than half of the world’s\\npopulation and a third of the land surface in high\\nresolution. We’ve found that one of the fi rst things\\nusers do after launching Google Earth is look at\\ntheir own home from space. Then they quickly\\ndiscover that Google Earth lets them search and\\nbrowse a growing web of geospatial content from\\ncommunity storytelling, 3D buildings, location\\nreferenced photos and historic maps to Wikipedia\\narticles, United Nations and European Space\\nAgency content, and even photos and stories from\\nNational Geographic and videos from Discovery\\nNetworks. Furthermore, Google Earth also enables\\npeople with limited resources to better understand\\nthe world around them.\\n\\nWe used Google technology to prove to the authorities that\\nthe land is fertile [so that the Indian government would\\ncompensate us at a higher rate in developing an SEZ\\n(Special Economic Zone)]. - ARUN SHIVKAR', 'pageNumber': '7'}]}\n",
            "692 {'id': '7ab937b24d675276e75de062f0171f86', 'source': 'gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2013_google_annual_report.pdf10', 'previous_segments': [], 'next_segments': [{'content': 'Android\\nWorking closely with the Open Handset Alliance, a business alliance of more than 75 technology and mobile companies, we\\ndeveloped Android, a free, fully open source mobile software platform that any developer can use to create applications for mobile\\ndevices and any handset manufacturer can install on a device. We believe Android will drive greater innovation and choice in the\\nmobile device ecosystem, and provide consumers with a more powerful mobile experience.\\nChromebook, Chrome, and Chromecast\\nAs mentioned above, we launched several new hardware products this year including multiple Chromebooks, Nexus 5 (smartphone),\\nNexus 7 (7” tablet), and Chromecast (device allowing the consumer to “cast” online content to their TV screen), all of which received\\nextremely positive user feedback.\\nGoogle+\\nGoogle+ allows users to share online just like users do in the real world, sharing different things with different people. As of\\nOctober 2013, we had 540 million 30-day active users across our Google properties.\\nGoogle Play\\nGoogle Play is our digital entertainment store for apps, music, books and movies. We also launched our All Access music service\\nthis year which allows users to listen to our vast music library. This year we brought Google Play to more platforms so Play Music,\\nPlay Movies and Play Books can now be enjoyed on the iPhone and iPad, in addition to Android devices.\\nGoogle Drive\\nGoogle Drive is a place where users can create, share, collaborate, and keep all of their stuff. Google Docs is built right into Google\\nDrive so users can work with others in real time on documents, spreadsheets and presentations and users’ files go everywhere\\nthey do. When users change a file on the web, on their computer, or on their mobile device, the file updates on every device\\nwhere users have installed Google Drive.\\nGoogle Wallet\\nGoogle Wallet is a virtual wallet that securely stores users’ credit and debit cards, offers, and rewards cards. Users can tap their\\nphone to pay in-store using Google Wallet anywhere contactless payments are accepted. Users can also easily pay online and\\non their mobile devices at participating merchant sites and apps using Google Wallet. People can also easily send money to their\\nfriends through Gmail or through the Google Wallet app.', 'pageNumber': '10'}]}\n",
            "2405 {'id': 'd286ea303da46422d26246d3d84e6bee', 'source': 'gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2015_google_annual_report.pdf5', 'previous_segments': [{'content': 'Helping you find information that gets you through\\nyour day extends well beyond the classic search\\nquery. Think, for example, of the number of photos\\nyou and your family have taken throughout your life,\\nall of your memories. Collectively, people will take\\n1 trillion photos this year with their devices. So we\\nlaunched Google Photos to make it easier for people\\nto organize their photos and videos, keep them\\nsafe, and be able to find them when they want to,\\non whatever device they are using. Photos launched\\nless than a year ago and already has more than\\n100 million monthly active users. Or take Google\\nMaps. When you ask us about a location, you don’t\\njust want to know how to get from point A to point\\nB. Depending on the context, you may want to\\nknow what time is best to avoid the crowds, whether\\nthe store you’re looking for is open right now, or\\nwhat the best things to do are in a destination you’re\\nvisiting for the first time.\\nBut all of this is just a start. There is still much work\\nto be done to make Search and our Google services\\nmore helpful to you throughout your day. You\\nshould be able to move seamlessly across Google\\nservices in a natural way, and get assistance that\\nunderstands your context, situation, and needs—\\nall while respecting your privacy and protecting\\nyour data. The average parent has different needs\\nthan the average college student. Similarly, a user\\nwants different help when in the car versus the\\nliving room. Smart assistance should understand\\nall of these things and be helpful at the right time,\\nin the right way.\\n\\nThe power of machine learning and\\nartificial intelligence\\nA key driver behind all of this work has been our\\nlong-term investment in machine learning and AI.\\nIt’s what allows you to use your voice to search for\\ninformation, to translate the web from one language\\nto another, to filter the spam from your inbox, to\\nsearch for “hugs” in your photos and actually pull\\nup pictures of people hugging…to solve many\\nof the problems we encounter in daily life. It’s what\\nhas allowed us to build products that get better over\\ntime, making them increasingly useful and helpful.\\nWe’ve been building the best AI team and tools\\nfor years, and recent breakthroughs will allow us\\nto do even more. This past March, DeepMind’s\\nAlphaGo took on Lee Sedol, a legendary Go master,\\nbecoming the first program to beat a professional\\nat the most complex game mankind ever devised.', 'pageNumber': '5'}], 'next_segments': []}\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_community import VertexAISearchRetriever\n",
        "\n",
        "vertex_search_retriever = VertexAISearchRetriever(\n",
        "   project_id=PROJECT_ID,\n",
        "   location_id=LOCATION,\n",
        "   data_store_id=DATASTORE_ID,\n",
        "   max_documents=3,\n",
        "   beta = True\n",
        ")\n",
        "\n",
        "\n",
        "result = vertex_search_retriever.invoke(query)\n",
        "print(len(result))\n",
        "\n",
        "for doc in result:\n",
        "   print(len(doc.page_content), doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_P6YeYg60TJi",
      "metadata": {
        "id": "_P6YeYg60TJi"
      },
      "source": [
        "## Building a RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TVsk0k1iHss5",
      "metadata": {
        "id": "TVsk0k1iHss5"
      },
      "source": [
        "Finally, with everything in place, we can build a beautiful RAG application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "GdaH85bmVYnM",
      "metadata": {
        "id": "GdaH85bmVYnM",
        "outputId": "6309db32-98fd-4c61-98df-7b43bad55016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Alphabet’s investment in the portfolio of Other Bets includes businesses that are at various stages of development, ranging from those in the R&D phase to those that are in the beginning stages of commercialization. These bets include emerging businesses across many industries, from improving transportation and health technology to exploring solutions to address climate change.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "llm = VertexAI(model_name=\"gemini-2.0-flash-001\", temperature=0.4, max_output_tokens=512)\n",
        "\n",
        "chain = (\n",
        "   {\"context\": vertex_search_retriever, \"question\": RunnablePassthrough()}\n",
        "   | prompt\n",
        "   | llm\n",
        "   | StrOutputParser()\n",
        ")\n",
        "\n",
        "\n",
        "chain.invoke(\"What are Alphabet's Other Bets?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5H8ZpZiTiqXB",
      "metadata": {
        "id": "5H8ZpZiTiqXB"
      },
      "source": [
        "## Query expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SUtpCA69X3XX",
      "metadata": {
        "id": "SUtpCA69X3XX"
      },
      "source": [
        "Query expansion is an attempt to reformulate queries to get a better (and broader) list of chunks.  One way of doing this is using `MultiQueryRetriever` component. Let's see how the amount of chunks increases after query expansion:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6arSZeUpXaul",
      "metadata": {
        "id": "6arSZeUpXaul",
        "outputId": "4f7f3b4a-51cd-4a34-a8e2-2a55705391f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "\n",
        "retriever_with_expansion = MultiQueryRetriever.from_llm(\n",
        "   retriever=vertex_search_retriever, llm=llm\n",
        ")\n",
        "\n",
        "result = vertex_search_retriever.invoke(query)\n",
        "print(len(result))\n",
        "\n",
        "\n",
        "result_expansion = retriever_with_expansion.invoke(query)\n",
        "print(len(result_expansion))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gyWTNb1WisPZ",
      "metadata": {
        "id": "gyWTNb1WisPZ"
      },
      "source": [
        "## Filtering out irrelevant chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CmS9vCNFiX9_",
      "metadata": {
        "id": "CmS9vCNFiX9_"
      },
      "source": [
        "Sometimes retrieval returns documents that are not really relevant, and they confuse the model. You can filter them by making additional pass through each document and asking the LLM to evaluate its relevance with `LLMChainFilter`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "gYeL6AkPhkQe",
      "metadata": {
        "id": "gYeL6AkPhkQe",
        "outputId": "cb074ad8-038d-43bd-a745-4cf4241d6207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28 11\n"
          ]
        }
      ],
      "source": [
        "from langchain.retrievers.document_compressors import LLMChainFilter\n",
        "\n",
        "# Retrieve many documents from the retrieval\n",
        "vertex_search_retriever_many = VertexAISearchRetriever(\n",
        "   project_id=PROJECT_ID,\n",
        "   location_id=LOCATION,\n",
        "   data_store_id=DATASTORE_ID,\n",
        "   beta = True,\n",
        "   max_documents=30,\n",
        ")\n",
        "results_many = vertex_search_retriever_many.invoke(query)\n",
        "\n",
        "\n",
        "llm_compression = VertexAI(temperature=0., model_name=\"gemini-2.0-flash-001\")\n",
        "chain_filter = LLMChainFilter.from_llm(llm=llm_compression)\n",
        "\n",
        "\n",
        "results_filtered_many = chain_filter.compress_documents(results_many, query)\n",
        "print(len(results_many), len(results_filtered_many))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qXG5B5-fqr5K",
      "metadata": {
        "id": "qXG5B5-fqr5K"
      },
      "source": [
        "And that's how you adjust the original chain to include filtering into your RAG:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ofmGzdfHhm6t",
      "metadata": {
        "id": "ofmGzdfHhm6t",
        "outputId": "7e7b707a-4fc7-4ccb-843d-787fd7a51918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Since the provided context is empty, I cannot answer the question. I have no information about how to improve LLM prompt performance.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "chain = (\n",
        "   {\"context\": vertex_search_retriever, \"question\": RunnablePassthrough()}\n",
        "   | RunnableLambda(lambda x: {\"context\": chain_filter.compress_documents(x[\"context\"], x[\"question\"]), \"question\": x[\"question\"]})\n",
        "   | prompt\n",
        "   | llm\n",
        "   | StrOutputParser()\n",
        ")\n",
        "\n",
        "\n",
        "chain.invoke(\"How can I make my LLM prompts perform better?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "utbrGAwpr8Mq",
      "metadata": {
        "id": "utbrGAwpr8Mq"
      },
      "source": [
        "Let's run extraction and compare the length of documents. We can observe a signifant reduction in the overall chunks' (and context) length:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "qwwF7EtCeGQS",
      "metadata": {
        "id": "qwwF7EtCeGQS",
        "outputId": "43281039-620a-4593-fd18-426ebadd9869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document reduced from 89 to 2800.\n",
            "Document reduced from 2800 to 692.\n",
            "Document reduced from 1104 to 2405.\n"
          ]
        }
      ],
      "source": [
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "llm_extractor = VertexAI(temperature=0., model_name=\"gemini-1.5-flash-001\")\n",
        "chain_extractor = LLMChainExtractor.from_llm(llm=llm_extractor)\n",
        "\n",
        "\n",
        "results_compressed = chain_filter.compress_documents(result_expansion, query)\n",
        "\n",
        "\n",
        "for original_doc, compressed_doc in zip(result_expansion, results_compressed):\n",
        " print(f\"Document reduced from {len(original_doc.page_content)} to {len(compressed_doc.page_content)}.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}