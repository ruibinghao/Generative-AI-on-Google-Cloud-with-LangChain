{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdmB51aFtL1b"
      },
      "source": [
        "## Vector Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rXcHboxHtL1c",
        "outputId": "5e35ddb2-f66e-4da8-aec3-480ea057210a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-2.0.28-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting langchain-google-community\n",
            "  Downloading langchain_google_community-2.0.7-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: bottleneck<2.0.0,>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai) (1.4.2)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.97.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai) (1.105.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai) (2.19.0)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai) (0.28.1)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-google-vertexai)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.67 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai) (0.3.72)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.6 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai) (2.11.0)\n",
            "Collecting pyarrow<20.0.0,>=19.0.1 (from langchain-google-vertexai)\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0,>=2.9 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai) (2.11.7)\n",
            "Collecting validators<1,>=0.22.0 (from langchain-google-vertexai)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.24.1 in /usr/local/lib/python3.11/dist-packages (from langchain-google-community) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client<3.0.0,>=2.161.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-community) (2.177.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-community) (2.4.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.70.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-community) (1.74.0)\n",
            "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-google-community)\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bottleneck<2.0.0,>=1.4.2->langchain-google-vertexai) (2.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.24.1->langchain-google-community) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.24.1->langchain-google-community) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.24.1->langchain-google-community) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.24.1->langchain-google-community) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.24.1->langchain-google-community) (2.32.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.161.0->langchain-google-community) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.161.0->langchain-google-community) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.161.0->langchain-google-community) (4.2.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (25.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (3.35.1)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (1.27.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (4.14.1)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (0.17.0)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai) (1.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (0.16.0)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-google-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-google-community) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-google-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-google-community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-google-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-google-community) (0.4.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.67->langchain-google-vertexai) (1.33)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.9->langchain-google-vertexai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.9->langchain-google-vertexai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.9->langchain-google-vertexai) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=2.24.1->langchain-google-community) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=2.24.1->langchain-google-community) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=2.24.1->langchain-google-community) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (0.14.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.161.0->langchain-google-community) (3.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.67->langchain-google-vertexai) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (0.3.9)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.24.1->langchain-google-community) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.24.1->langchain-google-community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=2.24.1->langchain-google-community) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain-google-vertexai) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_google_vertexai-2.0.28-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_community-2.0.7-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.6/99.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: validators, python-dotenv, pyarrow, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-google-vertexai, langchain-community, langchain-google-community\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 langchain-google-community-2.0.7 langchain-google-vertexai-2.0.28 marshmallow-3.26.1 mypy-extensions-1.1.0 pyarrow-19.0.1 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 validators-0.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-google-vertexai langchain-google-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHujRG5NtL1c",
        "outputId": "89ebcc50-d559-4b9b-e129-ab17d57041e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()\n",
        "\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "# Set your project and region\n",
        "PROJECT_ID = \"formal-truth-466615-g4\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "LOCATION = \"global\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TotMHT2itL1c"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXJ1SYd8tL1c"
      },
      "source": [
        "The `Embedding` class provides a standardized `Runnable` for embedding models.\n",
        "The key methods of this class are` embed_quer`y and` embed_document`sts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iBBL-FDQtL1d",
        "outputId": "dfc36c4c-c8fc-4906-d42e-d84e7e32cd4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "\n",
        "model_name = \"gemini-embedding-001\"\n",
        "embedding_model = VertexAIEmbeddings(model_name=model_name)\n",
        "\n",
        "single_embedding = embedding_model.embed_query(\"User query\")\n",
        "multiple_embeddings = embedding_model.embed_documents([\n",
        "\t\"Sample text 1\",\n",
        "\t\"Sample text 2\",\n",
        "\t\"Sample text 3\",\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xFAxHlntL1d"
      },
      "source": [
        "The argument `model_name` specifies the version of the VertexAI model to use.\n",
        "\n",
        "For the most up-to-date information on available versions and their capabilities, please\n",
        "refer to the official Vertex AI embedding model [documentation page](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBz_Q0LFtL1d"
      },
      "source": [
        "## VectorStores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meQalrbntL1d"
      },
      "source": [
        "The `VectorStore class` abstracts the entire vector search process at query time,\n",
        "providing a` similarity_searc`h method that accepts a query and returns a list of\n",
        "the most similar documents in the index\n",
        "\n",
        ". Optionally, you can add the paramete`r` k to\n",
        "specify how many similar documents you wish to retrieve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxfFQgK6tL1d"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai.vectorstores import VectorSearchVectorStore\n",
        "\n",
        "embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko-default\")\n",
        "\n",
        "vector_store = VectorSearchVectorStore.from_components(\n",
        "        project_id=os.environ[\"PROJECT_ID\"],\n",
        "        region=os.environ[\"REGION\"],\n",
        "        gcs_bucket_name=os.environ[\"GCS_BUCKET_NAME\"],\n",
        "        index_id=os.environ[\"INDEX_ID\"],\n",
        "        endpoint_id=os.environ[\"ENDPOINT_ID\"],\n",
        "        embedding=embeddings\n",
        ")\n",
        "\n",
        "documents = vector_store.similarity_search(\"user_query\", k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftn1JEOCtL1d"
      },
      "source": [
        "`VectorStore` instances can be converted into a standard retriever by invoking the\n",
        "`\n",
        "as_retrieve`r method, enabling the use of the basic retriever interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVvZ___LtL1d"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()\n",
        "documents = retriever.get_relevant_documents(\"user_query\", k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfvdTynftL1d"
      },
      "source": [
        "## VertexVectorSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCFwb28PtL1e"
      },
      "source": [
        "LangChain offers two distinct `VectorStores` for integration with Vector Search, each\n",
        "differentiated by the underlying Document Store they utilize.\n",
        "\n",
        "- ` VectorSearchVectorStor`\n",
        "uses Google Cloud Stora\n",
        "- `e VectorSearchVectorStoreDatasto` uses DataStorere\n",
        "re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAruUKlTtL1e"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import (\n",
        "    VectorSearchVectorStore, # GCS Document Store\n",
        "    VectorSearchVectorStoreDatastore, # DataStore Document store\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPwX_b4vtL1e"
      },
      "source": [
        "We can construct a `VectorSearchVectorStore` instance using the\n",
        "following snippet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npWF52fktL1e"
      },
      "outputs": [],
      "source": [
        "vector_store = VectorSearchVectorStoreDatastore.from_components(\n",
        "    project_id=\"my-project-id\",\n",
        "    region=\"my-region\",\n",
        "    index_id=\"my-index-name\",\n",
        "    endpoint_id=\"my-endpoint-name\",\n",
        "    embedding=embedding_model,\n",
        "    stream_update=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVR3ckF5tL1e"
      },
      "source": [
        "Regardless of your chosen storage backend (Datastore or Google Cloud Storage), the\n",
        "methods for interacting with the vector store remain consistent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb9clNaVtL1e"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"This is the first document\",\n",
        "    \"This is the second document\",\n",
        "    \"This is the third document\"\n",
        "]\n",
        "vector_store.add_texts(texts=texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paju-RpCtL1e"
      },
      "source": [
        "Optionally, if you anticipate using filtering later, you can enrich your documents with\n",
        "metadata during the addition process. This metadata will be stored both within Vector\n",
        "Search for efficient retrieval and in your chosen Document Store (either Datastore or\n",
        "Google Cloud Storage) for further processing or analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56eLAh6ytL1e"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"This is the first document\",\n",
        "    \"This is the second document\",\n",
        "    \"This is the third document\"\n",
        "]\n",
        "\n",
        "metadatas = [\n",
        "{\"page_number\": 1, \"length\": 10},\n",
        "{\"page_number\": 2, \"length\": 20},\n",
        "{\"page_number\": 3, \"length\": 5}\n",
        "]\n",
        "\n",
        "vector_store.add_texts(texts=texts, metadatas=metadatas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hulxadOHtL1e"
      },
      "source": [
        "We can use the `VectorStore` interface to perform similarity searches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svUmzfpWtL1e"
      },
      "outputs": [],
      "source": [
        "documents = vector_store.similarity_search(\"first\", k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJtlT0cntL1e"
      },
      "source": [
        "The following code snippet shows how to perform a similarity search\n",
        "using both numerical and string comparison filters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ATK5nAitL1e"
      },
      "outputs": [],
      "source": [
        "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import (\n",
        "    Namespace,\n",
        "    NumericNamespace,\n",
        ")\n",
        "\n",
        "filters = [Namespace(name=\"season\", allow_tokens=[\"spring\"])]\n",
        "numeric_filters = [NumericNamespace(name=\"price\", value_float=40.0, op=\"LESS\")]\n",
        "\n",
        "# Below code should return 2 results now\n",
        "vector_store.similarity_search(\n",
        "    \"shirt\", k=5, filter=filters, numeric_filter=numeric_filters\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyYOLIARtL1e"
      },
      "source": [
        "## CloudSQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdZQt9VWtL1e"
      },
      "source": [
        "To leverage the LangChain integration with Cloud SQL, you'll need to install an\n",
        "additional library alongside` langchain-google-ertexai`p:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efzD1EYAtL1e"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain-google-cloud-sql-pg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHlNIhdKtL1e"
      },
      "source": [
        "The initial step involves constructing the engine object.\n",
        "\n",
        "This object defines the Google\n",
        "Cloud project, location, database, and instance that the `VectorStore` will interact with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ac_i6cLtL1e"
      },
      "outputs": [],
      "source": [
        "from langchain_google_cloud_sql_pg import PostgresEngine\n",
        "\n",
        "engine = PostgresEngine.from_instance(\n",
        "    project_id=\"my-project-id\",\n",
        "    region=\"my-region\",\n",
        "    instance=\"my-instance-name\",\n",
        "    database=\"my-database-name\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXZ-hBOttL1e"
      },
      "source": [
        "Making use of the engine object we just created, we can use the\n",
        "`init_vectorstore_table` method to create the necessary table in the\n",
        "database if it doesn't already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQyFW_iLtL1e"
      },
      "outputs": [],
      "source": [
        "from langchain_google_cloud_sql_pg import Column\n",
        "\n",
        "engine.init_vectorstore_table(\n",
        "    table_name=\"my-table-name\",\n",
        "    vector_size=768,\n",
        "    metadata_columns=[Column(\"PRICE\", \"FLOAT\")],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmObp6LXtL1e"
      },
      "source": [
        "Once the engine and the table are in place, you can proceed to initialize the\n",
        "`VectorStore`.\n",
        "\n",
        "As with other integrations, you will also need to build an embedding\n",
        "model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WSHg0yctL1e"
      },
      "outputs": [],
      "source": [
        "from langchain_google_cloud_sql_pg import PostgresVectorStore\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "\n",
        "\n",
        "embedding = VertexAIEmbeddings(\n",
        "  model_name=\"textembedding-gecko@latest\",\n",
        "  project=\"my-project-id\"\n",
        ")\n",
        "\n",
        "store = PostgresVectorStore(\n",
        "    engine=engine,\n",
        "    table_name=\"my-table-name\",\n",
        "    embedding_service=embedding,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V2FyhKntL1f"
      },
      "source": [
        "You can add documents using the `add_documents` or `\n",
        "add_text`s methods.\n",
        "\n",
        " If you've created metadata columns, make sure to include thei\n",
        "values when adding documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TbI0Q80tL1f"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "all_texts = [\"Blue T-shirt\", \"Spring dress\", \"Black sunglasses\"]\n",
        "metadatas = [{\"PRICE\": 21.0}, {\"PRICE\": 23.0}, {\"PRICE\": 33.1}]\n",
        "ids = [str(uuid.uuid4()) for _ in all_texts]\n",
        "\n",
        "store.add_texts(all_texts, metadatas=metadatas, ids=ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w04NV0R4tL1f"
      },
      "source": [
        "To execute a similarity search, you can utilize the `similarity_search` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEBA0sdytL1f"
      },
      "outputs": [],
      "source": [
        "query = \"I want glasses\"\n",
        "docs = store.similarity_search(query, k=2, filter=\"PRICE <= 10\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeBzglcUtL1f"
      },
      "source": [
        "As a final note, to optimize query performance, this `VectorStore` also provides a method\n",
        "for creating and applying a vector index to the table, as illustrated below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdA_6HVJtL1t"
      },
      "outputs": [],
      "source": [
        "from langchain_google_cloud_sql_pg.indexes import IVFFlatIndex\n",
        "\n",
        "idx = IVFFlatIndex()\n",
        "store.apply_vector_index(idx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKHAHzdXtL1u"
      },
      "source": [
        "## BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxIUwLyEtL1u"
      },
      "outputs": [],
      "source": [
        "PROJECT = \"jzaldivar-test-project\"\n",
        "LOCATION = \"europe-west1\"\n",
        "DATASET = \"lcbook_dataset\"\n",
        "TABLE_NAME = \"my-table-name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5WKakR6tL1u"
      },
      "source": [
        "First, we create a dataset to store the data, using `google.cloud` bigquery client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3QT94pStL1u"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=PROJECT, location=LOCATION)\n",
        "client.create_dataset(dataset=DATASET, exists_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY07Fg6EtL1u"
      },
      "source": [
        "We must initialize a specialized `VectorStore` class to use\n",
        "VectorSearch in BigQuery. In this case, it is available through`\n",
        "langchaigoogle_n_communi`ty under the nam`BigQueryVectorStore`h\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvvNLi94tL1u"
      },
      "source": [
        "We must then initialize the specialized `VectorStore` class to use VectorSearch in Bigquery.\n",
        "\n",
        "It is available in the library `langchain_google_community`, under the name `BigQueryVectorStore`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyXOIoIztL1u"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain.vectorstores.utils import DistanceStrategy\n",
        "from langchain_google_community import BigQueryVectorStore\n",
        "\n",
        "embedding = VertexAIEmbeddings(\n",
        "  model_name=\"textembedding-gecko@latest\",\n",
        "  project=PROJECT\n",
        ")\n",
        "\n",
        "store = BigQueryVectorStore(\n",
        "    project_id=PROJECT,\n",
        "    dataset_name=DATASET,\n",
        "    table_name=TABLE_NAME,\n",
        "    location=LOCATION,\n",
        "    embedding=embedding,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkVHKxpbtL1u"
      },
      "source": [
        "The interface for adding texts to `BigQueryVectorStore` is consistent with other\n",
        "`VectorStore` subclasses. However, it's important to note that metadata, unlike in the\n",
        "CloudSQL integration, can only be stored within the designated `metadata_field` as\n",
        "a JSON object. This means you'll need to structure your metadata accordingly to\n",
        "leverage it for filtered searches within BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmHdZlnItL1u"
      },
      "outputs": [],
      "source": [
        "all_texts = [\n",
        "    \"Blue T-Shirt\",\n",
        "    \"Spring Dress\",\n",
        "    \"Black sunglasses\",\n",
        "]\n",
        "metadatas = [{\"len\": len(t)} for t in all_texts]\n",
        "\n",
        "store.add_texts(all_texts, metadatas=metadatas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m62_C3ltL1u"
      },
      "source": [
        "While basic filtering is supported in this way, the `BigQueryVectorStore`\n",
        "integration does not yet allow full SQL statement filtering. More complex filtering\n",
        "operations may require the use of raw SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LTu7xmFtL1u"
      },
      "outputs": [],
      "source": [
        "docs = store.similarity_search(\"I want a dress\", filter={\"len\": 12})\n",
        "print(docs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}